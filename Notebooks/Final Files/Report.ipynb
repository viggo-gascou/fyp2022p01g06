{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Year Project - Project 1 - Corona and Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Group 6 (F)**: Bjørn Søvad (bjso@itu.dk), Katarina Kraljevic (katkr@itu.dk), Mirka Katuscáková (katu@itu.dk), Emma Cecilie Bjerring Jensen (emcj@itu.dk), Viggo Yann Unmack Gascou (viga@itu.dk)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions for running this Jupyter Notebook\n",
    "Make sure to run this notebook in trusted mode. \\\n",
    "This will ensure that the code blocks run correctly and display the output correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries\n",
    "* [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "* [Numpy Documentation](https://numpy.org/doc/)\n",
    "* [Folium Documentation](https://python-visualization.github.io/folium/)\n",
    "* [Json Documentation](https://docs.python.org/3/library/json.html)\n",
    "* [Statsmodels Documentation](https://www.statsmodels.org/stable/)\n",
    "* [Scipy Documentation](https://scipy.github.io/devdocs/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing needed libraries\n",
    "import pandas as pd                                                            # provides major datastructure pd.DataFrame() to store the datasets\n",
    "import numpy as np                                                             # used for numerical calculations and fast array manipulations\n",
    "import folium                                                                  # used for spatial data visualizations\n",
    "import json                                                                    # used for loading json data correctly\n",
    "import statsmodels.api as sm                                                   # used to run multivariate linear regression\n",
    "from scipy.stats import pearsonr, spearmanr                                    # used to run `pearson` and `spearman` association tests of numerical variables on two variables\n",
    "from statsmodels.stats.multitest import multipletests                          # used to run multiple tests of p-values for multiple variables\n",
    "from IPython.display import Markdown, display                                  # used to print stuff with markdown/HTML formatting for bold text and colors\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the raw corona data from Germany\n",
    "corona_df = pd.read_csv('../../data/raw/corona/de_corona.csv', sep = '\\t')\n",
    "corona_df.name = 'corona_df'\n",
    "\n",
    "#Importing the raw weather data for the countries, Germany, Netherlands, Sweden and Denmark\n",
    "weather_df = pd.read_csv(\"../../data/raw/weather/weather.csv\")\n",
    "weather_df.name = 'weather_df'\n",
    "\n",
    "#Loading in the metadata json using the Python json library\n",
    "with open('../../data/raw/metadata/de_metadata.json','r', encoding=\"utf8\") as f:\n",
    "    country_metadata=json.load(f)\n",
    "\n",
    "#Creating a folium map (called de_map) that is based around Germany and uneditable in terms of placement and zoom\n",
    "de_map = folium.Map(location = [51.1657, 10.4515], zoom_start = 6, crs = 'EPSG3857', \n",
    "    zoom_control = False, scrollWheelZoom = False, dragging = False)\n",
    "\n",
    "#Loading in the geojson that contains data for the regions and borders of Germany and adding it to the folium map\n",
    "folium.GeoJson('../../data/raw/shapefiles/de.geojson', name = \"geojson\").add_to(de_map)\n",
    "folium.LayerControl().add_to(de_map);\n",
    "de_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0: Data filtering and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data analysis done in this notebook is done with a handful of different datasets:\n",
    "\n",
    "> CSV: Corona (DE) - Contains the Number of new infections (per day) and Number of new casualties (per day) filtered by day and region in Germany for each day in the period `2020-01-02` to `2021-02-21`.\n",
    ">\n",
    "> CSV: Weather - Contains information about several indicators of weather conditions for each region in Germany, Denmark, Sweden and Netherlands for each day in the period `2020-02-13` to `2021-02-21`\n",
    ">\n",
    "> JSON: Metadata (DE) - Contains more information on the population in the different regions in Germany\n",
    ">\n",
    "> GEOJSON: Geojson (DE) - Holds the geojson data for the different regions in Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial inspection of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, cols = weather_df.shape\n",
    "print(\"Number of Rows: \" + str(row))\n",
    "print(\"Number of Columns: \" + str(cols))\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `weather` dataset contains `9` different variables for the countries Germany, Denmark Sweden and Netherlands spread across `20220` rows and `9` columns. Each row contains `7` different weather measurements for a particular day in a specific country and region:\n",
    "> `Date` (YYY-DD-MM): Is the day of which the weather measurements were made and reported\n",
    ">\n",
    "> `Iso3166-2`: Is the [ISO 3166-2](https://en.wikipedia.org/wiki/ISO_3166-2) code for the region for which the weather measurements were made\n",
    ">\n",
    "> `Relative Humidity Surface` (%): Is the **daily average** relative humidity of the surface\n",
    ">\n",
    "> `Solar Radiation`(W/m^2): Is the **daily sum** of the solar radiation from the sun\n",
    ">\n",
    "> `Surface Pressure` (Pa): Is the **daily sum** of the atmospheric pressure at the surface of the earth\n",
    ">\n",
    "> `TemperatureAboveGround` (º K): Is the **daily average** of the temperature above ground\n",
    ">\n",
    "> `Total Precipitation` (mm): Is the **daily sum** of the total precipitation \n",
    ">\n",
    "> `UV Index` (Scale 1-5): Is the **daily sum** of the strength of the ultraviolet radiation\n",
    ">\n",
    "> `Wind Speed`(m/s): Is the **daily average** of the wind speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, cols = corona_df.shape\n",
    "print(\"Number of Rows: \" + str(row))\n",
    "print(\"Number of Columns: \" + str(cols))\n",
    "corona_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `corona` dataset contains `4` different variables for corona reports for Germany spread across `5602` rows and `4` columns. Each row contains `2` different corona reports for a particular day in a specific country and region:\n",
    "> `Date` (YYY-DD-MM): Is the day of which the corona report was made\n",
    ">\n",
    "> `Region Code`: Is the region code for the region for which the corona report was made\n",
    ">\n",
    "> `Confirmed Addition`: Is the number of new confirmed infections of corona for the specific day in the specified region\n",
    ">\n",
    "> `Deceased Addition`: Is the number of newly confirmed deaths for the specific day in the specified region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "Checking to see if there are any missing (Na or NaN) values in either of the two datasets \\\n",
    "\\\n",
    "We also check if there are any duplicate rows in either of the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [weather_df, corona_df]\n",
    "for dataset in datasets:\n",
    "    if dataset.name == \"weather_df\":\n",
    "        printmd(\"### **Weather Dataset**\")\n",
    "    else: \n",
    "        printmd(\"### **Corona Dataset**\")\n",
    "\n",
    "    print(dataset.isnull().any())\n",
    "    print(\"-----------------------------------------------\")\n",
    "    printmd( \"##### <span style='color:red'> ❌ **Oh No! There are missing data values in the dataset!**</span>\" if dataset.isnull().any().any() \n",
    "            else\n",
    "            \"##### <span style='color:lightgreen'> ✅ **Great! There are no missing data values in the dataset!**</span>\")\n",
    "    printmd(\"____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    if dataset.name == \"weather_df\":\n",
    "        printmd(\"### **Weather Dataset**\")\n",
    "    else: \n",
    "        printmd(\"### **Corona Dataset**\")\n",
    "\n",
    "    print(dataset.duplicated())\n",
    "    print(\"-----------------------------------------------\")\n",
    "    printmd( \"##### <span style='color:red'> ❌ **Oh No! There are duplicate data values in the dataset!**</span>\" if dataset.duplicated().any() \n",
    "            else\n",
    "            \"##### <span style='color:lightgreen'> ✅ **Great! There are no duplicate data values in the dataset!**</span>\")\n",
    "    printmd(\"____\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no missing data values we can move on to cleaning and filtering the data.\n",
    "\n",
    "#### _Let's start by cleaning and filtering the corona data for Germany:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first start of by creating to dictionaries that are going to help us to map both regions and their populations to the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary that contains the full names of the different regions as keys and their respective iso3166-2 code as values\n",
    "region_map = {country_metadata[\"country_metadata\"][i][\"covid_region_code\"]: \n",
    "    country_metadata[\"country_metadata\"][i][\"iso3166-2_code\"] for i in range(len(country_metadata[\"country_metadata\"]))}\n",
    "\n",
    "#Creating a dictionary that contains the full names of the different regions as keys and their respective populations as values\n",
    "population_map = {country_metadata[\"country_metadata\"][i][\"iso3166-2_code\"]: \n",
    "    country_metadata[\"country_metadata\"][i][\"population\"] for i in range(len(country_metadata[\"country_metadata\"]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the region_map we can create extra columns to add the iso3166-2 code to the corona dataframe as it only contained to full region codes. \\\n",
    "\\\n",
    "We can also use the population_map to add a column with the population of each of the regions to the corona dataframe. \\\n",
    "\\\n",
    "With the population column we can create a column that contains the cases and deaths per capita using the confirmed addition and the population column we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the region_map dictionary to create a new column with the respective iso3166-2 code for each region based on the full region name\n",
    "#from the region_code column\n",
    "corona_df[\"iso3166-2\"] = corona_df[\"region_code\"].map(region_map)\n",
    "\n",
    "#Using the population_map dictionary to create a new column with the respective population for each region based on the iso3166-2 code\n",
    "#from the iso3166-2 column\n",
    "corona_df[\"population\"] = corona_df[\"iso3166-2\"].map(population_map)\n",
    "\n",
    "#Also adding a cases and deaths per capita column that is created using the confirmed covid cases and deaths respectively divided by the population in that region\n",
    "corona_df[\"cases_pc\"] = corona_df[\"confirmed_addition\"] / corona_df[\"population\"]\n",
    "corona_df[\"deaths_pc\"] = corona_df[\"deceased_addition\"] / corona_df[\"population\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Now moving on to the weather dataset:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start of by first filtering out all the other countries from the dataset as we are not interested in their data.\\\n",
    "\\\n",
    "We can then convert the temperature measurements from º K to º C, we do that by subtracting `273.15` from each row value in the temperature measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out all the weather data that is not relevant as we are only interested in weatherdata from Germany\n",
    "weather_df = weather_df[weather_df[\"iso3166-2\"].str.startswith(\"DE\")]\n",
    "\n",
    "#Converting the temperature from Kelvin to Celsius\n",
    "weather_df[\"TemperatureAboveGround\"] = weather_df[\"TemperatureAboveGround\"] - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can merge the corona_df and the weather_df to create on big dataframe/dataset that contains all the data that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the weatherdata with the coronadata to create one dataframe with all the data that we need\n",
    "merged_df = corona_df.merge(weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now having cleaned and filtered to two datasets we can create new `.csv` files that we can use for the rest of this notebook. \\\n",
    "\\\n",
    "We do this by using the built-in pandas function `pd.to_csv` that will automatically convert the pandas dataframe to a `.csv` file \\\n",
    "\\\n",
    "We will also create shortcuts to those files so the code becomes more human readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pd.to_csv function is run by first specifying the file path and name that it should create.\n",
    "# The index = False argument specifies to the function that the .csv file should not include the index\n",
    "# that the pandas dataframe has\n",
    "corona_df.to_csv(\"../../Data/processed/de_corona.csv\", index = False)\n",
    "weather_df.to_csv(\"../../Data/processed/de_weather.csv\", index = False)\n",
    "merged_df.to_csv(\"../../Data/processed/de_corona_weather.csv\", index = False)\n",
    "\n",
    "# Now creating the shortcuts to the now processed datasets\n",
    "corona_path = \"../../Data/processed/de_corona.csv\"\n",
    "weather_path = \"../../Data/processed/de_weather.csv\"\n",
    "merged_path = \"../../Data/processed/de_corona_weather.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read in and overwrite the name variables of the datasets to make sure that the data we use has been filtered and cleaned correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df = pd.read_csv(corona_path)\n",
    "weather_df = pd.read_csv(weather_path)\n",
    "merged_df = pd.read_csv(merged_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Single variable analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b989256eb56f7c452f8df4a64159a114113bfaae6a03bedf3a667d033260f0d6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
